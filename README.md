<!--
MTS SRE Course 2023 (c) SunnyKi
-->
# Модуль 6: Нагрузочное тестирование
## 1. Профиль нагрузки

Стандартный профиль нагрузки для сайта прогноза погоды должен выглядеть так:
- пользователь запрашивает список городов;
- выбирает интересующий город и смотрит по нему прогноз;
- в 10% случаев пользователь делает запрос прогноза погоды по всем городам.
Так как у `API` нет функции запроса прогноза погоды по `ID города` (только по `ID прогноза`), в тестировании запроса погоды по интересующему городу мы ограничимся вызовом списка городов и полного списка прогноза погоды.
Так как заполнение базы сайта должно происходить во внутреннем контуре системы и в плановом режиме, мы можем принебречь ее влиянием на производительность системы.

## 2. Инструмент НТ

В качестве инструмента для нагрузочного тестирования выбран `k6`.
Преимущества:
 - простота установки, 
 - высокая производительность,
 - использование минимальных системных ресурсов,
 - интеграция с CI Gitlab,
 - автоматичсекое прерывание тестов по критериям,
 - открытая модель тестирования,
 - широкий выбор стратегий,
 - наличие cloud-версии.
Для проведения тестов был выбран сценарий с исполнителем ramping-arrival-rate в виду того, что он реализован на концепции открытой модели, что более точно позволяет симитировать реальный условия. 
Предварительно проводим кратковременный стресс тест для выяснения максимальной производительности сайта при выполнении SLO.
После этого выполняем нагрузочный тест, приближенный к максимальной нагрузке с выполнением SLO, достаточно продолжительное время, для того, чтобы убедиться в работоспособности и стабильности показателей сайта при высокой нагрузке.

## 3. Требования  по производительности системы (SLO/SLA)

95 процентов запросов должны укладываться в задержку не более `250 ms`.
Количество http ошибок не должно превышать `1%`.

## 4. Максимальная производительность

При данной конфигурации `API` сервиса (3 реплики с лимитами cpu: 100m memory:128Mi ) достигается производительность в `643 rps` с соблюдением требования задержки не более `250 ms` у 95 процентов запросов, при этом количество ошибок не превышает `1%`.

## 5. Вывод

При выполнении стресс теста максимальная производительность сайта составила `643 rps` при частоте `16 итераций в секунду`. При этом количество VU достигало 100. 
![стресс тест, производительность](screenshots\k6-stress-traffic.png)
Далее шла резкая деградация производительности, увеличение времени отклика p95 вплоть до 5 сек. В некоторых случаях появлялись 499 http ошибки.
![стресс тест, задержки](screenshots\k6-stress-latency.png)
![стресс тест, отчет к6](screenshots\k6-stress-report.png)
Нарушение требования по производительности происходит при превышении 16 итераций в секунду.
При этом загрузка CPU на подах API была 99%, что говорит нам о том, что это является узким местом в системе.
![стресс тест, ресурсы](screenshots\k6-stress-saturation.png)
Узким местом в системе является ограничение ресурса CPU.

Далее провел нагрузочный тест с частотой `12 итераций в секунду (75% от максимума)` с продолжительностью в `60 минут`, с целью убедиться в стабильности работы сайта под данной нагрузкой.
![нагрузочный тест, отчет к6](screenshots\k6-report.png)
При данной нагрузке поведение системы оставалось стабильным при поддержании производительности около `500 rps и соблюдении SLO/SLA` (максимальная задержка p95 по метрикам ingress была в пределах 190ms, при отсутствии ошибок). При этом по метрикам `k6`, т.е. со стороны клиента, не превышала 280ms. 
![нагрузочный тест, производительность](screenshots\k6-load-traffic.png)
![нагрузочный тест, ошибки](screenshots\k6-load-errors.png)
Были зафиксированы просадки по задержке ответа до 640ms общей продолжительностью не более 4 минут без потери производительности системой. Это могло быть связано с проведением нагрузочных тестов коллегами по обучению. После просадок задержка возвращалась к норме.
![нагрузочный тест, задержки](screenshots\k6-load-latency.png)
`Для дальнейшего увеличения увеличения производительности при соблюдении SLO/SLA необходимо увеличения CPU ресурса и/или количества реплик.` 
![нагрузочный тест, ресурсы](screenshots\k6-load-saturation.png)
Так же следует учитывать, что тестирование проводилось на текущем объеме данных. При увеличении объема возможно появление другого узкого места (сервер БД, канал передачи данных и т.п.).

> P.S. тестирование проводилось на домашнем немолодом ПК, что так же могло внести свою лепту в виде кратковременных аномалий.
Для проверки данной гипотезы был проведен распределенный cloud тест с помощью Job-а из кластера. Результаты:
![cloud тест, зона Colambus](screenshots\k6-cloud.png)
Как видим, в них так же присутствуют просадкеи до 500ms. Наиболее правдоподобным объяснением является предыдущее предположение о проведении НТ коллегами по обучению.
